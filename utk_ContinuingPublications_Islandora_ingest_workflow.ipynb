{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utk libraries Continuing Publications\n",
    "\n",
    "# Islandora ingest workflow\n",
    "\n",
    "#### jeremy.d.moore@utk.edu\n",
    "\n",
    "1. Using Adobe Acrobat DC, export PDF to 300 ppi TIFFs from Adobe Acrobat DC into properly named folders per volume\n",
    "2. Rename files then create ingest directory and Zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_formatted_extension(from_extension, remediate=False):\n",
    "    '''\n",
    "    -- Purpose --\n",
    "    Returns an extension that:\n",
    "    1. has a period in the front\n",
    "    2. Optional: is lower-case\n",
    "    3. Optional: return jpeg as jpg and tiff as tif\n",
    "\n",
    "    -- Arguments --\n",
    "    from_extension: type=string; file extension with or without a '.'\n",
    "\n",
    "    -- Returns --\n",
    "    formatted_extension: type=string; formatted extension\n",
    "    '''\n",
    "    # make sure there's a period at the front of the extension\n",
    "    if from_extension.startswith('.'):  # do nothing\n",
    "        formatted_extension = from_extension\n",
    "    else:  # add a period\n",
    "        formatted_extension = f'.{from_extension}'\n",
    "\n",
    "    # make it lower-case\n",
    "    if remediate:\n",
    "        formatted_extension = formatted_extension.lower()\n",
    "        # hard-coded alterations for jpeg and tiff\n",
    "        if formatted_extension == '.jpeg':\n",
    "            formatted_extension = '.jpg'\n",
    "        elif formatted_extension == '.tiff':\n",
    "            formatted_extension = '.tif'\n",
    "\n",
    "    return formatted_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     3,
     6,
     28,
     47,
     68,
     84
    ]
   },
   "outputs": [],
   "source": [
    "class ContinuingPublications_Volume:\n",
    "    '''Common base class for Continuing Publications'''\n",
    "\n",
    "    def __init__(self, directory):\n",
    "        self.directory_path = Path(directory).resolve()\n",
    "\n",
    "    def backup_volume(self):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Copy all files in directory to backup directory with name: <directory>_backup\n",
    "\n",
    "        -- Arguments --\n",
    "        None\n",
    "\n",
    "        -- Returns --\n",
    "        backup_directory_path: type=Path-like object; returns absolute path to backup directory\n",
    "        '''\n",
    "        backup_directory_name = f'{self.directory_path.name}_backup'\n",
    "        backup_directory_path = self.directory_path.parents[0].joinpath(backup_directory_name)\n",
    "\n",
    "        if backup_directory_path.exists():  # shutil.copytree requires directory to NOT exist\n",
    "            shutil.rmtree(backup_directory_path)\n",
    "\n",
    "        shutil.copytree(self.directory_path, backup_directory_path)\n",
    "\n",
    "        if backup_directory_path.exists():\n",
    "            return backup_directory_path.resolve()\n",
    "\n",
    "    def remove_backup(self):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Deletes the backup volume created by self.backup_volume()\n",
    "\n",
    "        -- Arguments --\n",
    "        None\n",
    "\n",
    "        -- Returns --\n",
    "        True/False: type=boolean; True/False result of _backup.is_dir()\n",
    "        '''\n",
    "        backup_directory_name = f'{self.directory_path.name}_backup'\n",
    "        backup_directory_path = self.directory_path.parents[0].joinpath(backup_directory_name)\n",
    "\n",
    "        # remove backup directory\n",
    "        shutil.rmtree(backup_directory_path)\n",
    "\n",
    "        return backup_directory_path.is_dir()\n",
    "\n",
    "    def undo_backup(self):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Deletes the processed directory and renames the backup directory to the\n",
    "        original directory name\n",
    "\n",
    "        -- Arguments --\n",
    "        None\n",
    "\n",
    "        -- Returns --\n",
    "        None\n",
    "        '''\n",
    "        backup_directory_name = f'{self.directory_path.name}_backup'\n",
    "        backup_directory_path = self.directory_path.parents[0].joinpath(backup_directory_name)\n",
    "\n",
    "        # remove processed directory\n",
    "        shutil.rmtree(self.directory_path)\n",
    "\n",
    "        # rename backup directory to original directory name\n",
    "        backup_directory_path.rename(self.directory_path)\n",
    "\n",
    "    def get_file_paths(self, with_extension):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Get all file Paths with_extension in self.directory_path\n",
    "\n",
    "        -- Arguments --\n",
    "        with_extension: type=string; extension to use for globbing\n",
    "\n",
    "        -- Returns --\n",
    "        file_paths_list: type:list; list of Path-like objects, 1 Path-like object\n",
    "        per file_path in self.directory_path\n",
    "        '''\n",
    "        formatted_extension = get_formatted_extension(with_extension)\n",
    "        file_paths_list = sorted(self.directory_path.glob(f'*{formatted_extension}'))\n",
    "        return file_paths_list\n",
    "\n",
    "    def rename_files_to_directory_name(self, with_extension, zerofill=4):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Rename all files {with_extension} to {self.directory_path.name}_{str(index).zfill(zerofill)}\n",
    "        *Note: will currently remediate extensions to lower-case and change tiff/jpeg to tif/jpg\n",
    "\n",
    "        -- Arguments --\n",
    "        with_extension: type=string; extension to rename\n",
    "        zerofill: type=integer; how many digits to zeropad\n",
    "\n",
    "        -- Returns --\n",
    "        None\n",
    "        '''\n",
    "        formatted_extension = get_formatted_extension(with_extension)\n",
    "\n",
    "        # extension will be lower-case and tif/jpg instead of tiff/jpeg\n",
    "        remediated_extension = get_formatted_extension(with_extension, remediate=True)\n",
    "\n",
    "        # get total number of files and the paths for files to rename\n",
    "        file_paths_list = self.get_file_paths(formatted_extension)\n",
    "        number_of_files = len(file_paths_list)\n",
    "\n",
    "        backup_directory_path = self.backup_volume()\n",
    "\n",
    "        if backup_directory_path.exists():\n",
    "            print(f'Backup directory created at {backup_directory_path}')\n",
    "\n",
    "        print(f'Renaming {number_of_files} \"{formatted_extension}\"s in {self.directory_path.name} . . .')\n",
    "\n",
    "        count = 0\n",
    "        for index, file_path in enumerate(file_paths_list, start=1):\n",
    "            new_file_name = f'{self.directory_path.name}_{str(index).zfill(zerofill)}{remediated_extension}'\n",
    "            new_file_path = file_path.parents[0].joinpath(new_file_name)\n",
    "            file_path.rename(new_file_path)\n",
    "            count = index\n",
    "\n",
    "        print(f' Renamed {count} \"{formatted_extension}\"s')\n",
    "\n",
    "    def create_islandora_ingest_directory(self):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Create Islandora ingest directory with TIFF in nested structure\n",
    "\n",
    "        -- Arguments --\n",
    "        None\n",
    "\n",
    "        -- Returns --\n",
    "        ingest_directory_path: type=Path-like object; Path to the directory for ingest\n",
    "        '''\n",
    "        import datetime\n",
    "\n",
    "        # get image paths and number of images\n",
    "        extension = 'tif'\n",
    "        image_paths_list = self.get_file_paths(extension)\n",
    "        number_of_images = len(image_paths_list)\n",
    "\n",
    "        # set ingest stub to add to directory name\n",
    "        ingest_stub = 'CreatedForIslandoraIngest'\n",
    "        # get today's date in YYYY-MM-DD format and add to ingest stub\n",
    "        todays_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "        ingest_stub = f'{ingest_stub}_{todays_date}'\n",
    "\n",
    "        # create ingest directory\n",
    "        ingest_directory_name = f'{self.directory_path.name}_{ingest_stub}'\n",
    "        ingest_directory_path = self.directory_path.parents[0].joinpath(ingest_directory_name)\n",
    "        try:\n",
    "            ingest_directory_path.mkdir()\n",
    "        except FileExistsError:  # directory already exists\n",
    "            print(f'WARNING: ingest directory already exists at {ingest_directory_path}')\n",
    "\n",
    "        print(f'Processing {number_of_images} images in {self.directory_path.name} for ingest . . .')\n",
    "\n",
    "        # for each image\n",
    "        for index, image_path in enumerate(image_paths_list, start=1):\n",
    "            \n",
    "            # sort order isn't working for Islandora ingest so try something stupid\n",
    "            if index == 1:  # leave 1 as-is\n",
    "                directory_index = index\n",
    "            else:  # otherwise add 10\n",
    "                directory_index = index + 10\n",
    "\n",
    "            # create a sub-directory with the index number + 10 to go around the Islandora sorting issue\n",
    "            image_subdirectory_path = ingest_directory_path.joinpath(str(directory_index))\n",
    "            try:\n",
    "                image_subdirectory_path.mkdir()\n",
    "            except FileExistsError:\n",
    "                print(f'Sub-directory already exists at {image_subdirectory_path}')\n",
    "\n",
    "            # set new image name and copy path, then copy image\n",
    "            new_image_name = f'page {str(index)}{image_path.suffix}'\n",
    "            copy_image_path = image_subdirectory_path.joinpath(new_image_name)\n",
    "            shutil.copyfile(image_path, copy_image_path)\n",
    "        \n",
    "        page_directory_paths_list = [x for x in ingest_directory_path.iterdir() if x.is_dir()]\n",
    "        number_of_page_directories = len(page_directory_paths_list)\n",
    "        \n",
    "        if number_of_page_directories == number_of_images:\n",
    "            print(f'  {number_of_page_directories} pages processed')\n",
    "\n",
    "        return ingest_directory_path\n",
    "\n",
    "    def create_zip_file(self, directory_to_zip):\n",
    "        '''\n",
    "        -- Purpose --\n",
    "        Create a zip file from directory_path\n",
    "        To be used with create_islandora_ingest_directory\n",
    "\n",
    "        -- Arguments --\n",
    "        directory_path: type=Path-like object; directory to compress into a Zip file\n",
    "\n",
    "        -- Returns --\n",
    "        True/False: type=boolean; whether or not {directory_path.name}.zip exists\n",
    "        in {directory_path.parents[0]}\n",
    "        '''\n",
    "        directory_to_zip_path = Path(directory_to_zip)\n",
    "        print(f'Processing {directory_to_zip_path.name} into a Zipfile . . .')\n",
    "        shutil.make_archive(self.directory_path, \"zip\", root_dir=directory_to_zip_path)\n",
    "        zip_path = directory_to_zip_path.parents[0].joinpath(f'{self.directory_path.name}.zip')\n",
    "        if zip_path.is_file():\n",
    "            zip_path_size = round((zip_path.stat().st_size / 1024 / 1024), 2)\n",
    "            if zip_path_size > 500:\n",
    "                print(f'WARNING: {zip_path.name} is OVER 500 MB, write logic to split up Zip Files right meow!')\n",
    "            else:\n",
    "\n",
    "                print(f'  {zip_path.name} is {zip_path_size} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory with book directories to process\n",
    "directory_to_process_path = Path('data/Phoenix/work/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing phoenix_2015fall . . .\n",
      "Backup directory created at /Users/jeremy/Documents/GitHub/utk_ContinuingPublications/data/Phoenix/work/phoenix_2015fall_backup\n",
      "Renaming 33 \".tiff\"s in phoenix_2015fall . . .\n",
      " Renamed 33 \".tiff\"s\n",
      "Processing 33 images in phoenix_2015fall for ingest . . .\n",
      "  33 pages processed\n",
      "Processing phoenix_2015fall_CreatedForIslandoraIngest_2019-03-12 into a Zipfile . . .\n",
      "  phoenix_2015fall.zip is 192.29 MB\n",
      "\n",
      "Processing phoenix_2016spring . . .\n",
      "Backup directory created at /Users/jeremy/Documents/GitHub/utk_ContinuingPublications/data/Phoenix/work/phoenix_2016spring_backup\n",
      "Renaming 36 \".tiff\"s in phoenix_2016spring . . .\n",
      " Renamed 36 \".tiff\"s\n",
      "Processing 36 images in phoenix_2016spring for ingest . . .\n",
      "  36 pages processed\n",
      "Processing phoenix_2016spring_CreatedForIslandoraIngest_2019-03-12 into a Zipfile . . .\n",
      "  phoenix_2016spring.zip is 36.52 MB\n",
      "\n",
      "Processing phoenix_2017spring . . .\n",
      "Backup directory created at /Users/jeremy/Documents/GitHub/utk_ContinuingPublications/data/Phoenix/work/phoenix_2017spring_backup\n",
      "Renaming 36 \".tiff\"s in phoenix_2017spring . . .\n",
      " Renamed 36 \".tiff\"s\n",
      "Processing 36 images in phoenix_2017spring for ingest . . .\n",
      "  36 pages processed\n",
      "Processing phoenix_2017spring_CreatedForIslandoraIngest_2019-03-12 into a Zipfile . . .\n",
      "  phoenix_2017spring.zip is 83.98 MB\n",
      "\n",
      "Processing phoenix_2018spring . . .\n",
      "Backup directory created at /Users/jeremy/Documents/GitHub/utk_ContinuingPublications/data/Phoenix/work/phoenix_2018spring_backup\n",
      "Renaming 36 \".tiff\"s in phoenix_2018spring . . .\n",
      " Renamed 36 \".tiff\"s\n",
      "Processing 36 images in phoenix_2018spring for ingest . . .\n",
      "  36 pages processed\n",
      "Processing phoenix_2018spring_CreatedForIslandoraIngest_2019-03-12 into a Zipfile . . .\n",
      "  phoenix_2018spring.zip is 80.27 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all directories in {directory_to_process_path}\n",
    "\n",
    "# create list of paths to each book directory\n",
    "book_directory_paths_list = sorted([x for x in directory_to_process_path.iterdir() if x.is_dir()])\n",
    "\n",
    "for book_directory_path in book_directory_paths_list:\n",
    "    \n",
    "    print(f'Processing {book_directory_path.name} . . .')\n",
    "    \n",
    "    # instantiate book\n",
    "    book = ContinuingPublications_Volume(book_directory_path)\n",
    "    \n",
    "    # rename files\n",
    "    if platform.system() == 'Windows':\n",
    "        # default Acrobat DC TIFF export name on Windows\n",
    "        book.rename_files_to_directory_name('.tif')\n",
    "    else: # default Acrobat DC TIFF filename on Mac\n",
    "        book.rename_files_to_directory_name('.tiff')\n",
    "    \n",
    "    # create ingest directory tagged with Today's date\n",
    "    ingest_directory = book.create_islandora_ingest_directory()\n",
    "    \n",
    "    # create ingest Zipfile\n",
    "    book.create_zip_file(ingest_directory)\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS ONLY WORKS IF BASE DIRECTORY HAS 1 UNDERSCORE!!!\n",
      "\n",
      "Processing phoenix_2015fall . . .\n",
      "Adding phoenix_2015fall_CreatedForIslandoraIngest_2019-03-12 to remove list\n",
      "\n",
      "Adding phoenix_2015fall_backup to remove list\n",
      "\n",
      "Processing phoenix_2016spring . . .\n",
      "Adding phoenix_2016spring_CreatedForIslandoraIngest_2019-03-12 to remove list\n",
      "\n",
      "Adding phoenix_2016spring_backup to remove list\n",
      "\n",
      "Processing phoenix_2017spring . . .\n",
      "Adding phoenix_2017spring_CreatedForIslandoraIngest_2019-03-12 to remove list\n",
      "\n",
      "Adding phoenix_2017spring_backup to remove list\n",
      "\n",
      "Processing phoenix_2018spring . . .\n",
      "Adding phoenix_2018spring_CreatedForIslandoraIngest_2019-03-12 to remove list\n",
      "\n",
      "Adding phoenix_2018spring_backup to remove list\n",
      "\n",
      "Deleting phoenix_2015fall_CreatedForIslandoraIngest_2019-03-12\n",
      "phoenix_2015fall_backup no longer exists\n",
      "Deleting phoenix_2016spring_CreatedForIslandoraIngest_2019-03-12\n",
      "phoenix_2016spring_backup no longer exists\n",
      "Deleting phoenix_2017spring_CreatedForIslandoraIngest_2019-03-12\n",
      "phoenix_2017spring_backup no longer exists\n",
      "Deleting phoenix_2018spring_CreatedForIslandoraIngest_2019-03-12\n",
      "phoenix_2018spring_backup no longer exists\n",
      "Directories in /Users/jeremy/Documents/GitHub/utk_ContinuingPublications/data/Phoenix/work\n",
      "phoenix_2015fall\n",
      "phoenix_2016spring\n",
      "phoenix_2017spring\n",
      "phoenix_2018spring\n"
     ]
    }
   ],
   "source": [
    "# NUCLEAR OPTION TO AUTOMATE DIRECTORY RESET FOR TESTING -- USE AT OWN RISK\n",
    "\n",
    "# THIS ONLY WORKS IF BASE DIRECTORY HAS 1 UNDERSCORE!!!\n",
    "# Undo backups directories in {directory_to_process_path} and delete ingest folders, i.e. reset directory to re-process\n",
    "# set directory with book directories to process\n",
    "directory_to_process_path = Path('data/Phoenix/work/')\n",
    "\n",
    "print('THIS ONLY WORKS IF BASE DIRECTORY HAS 1 UNDERSCORE!!!')\n",
    "print('')\n",
    "\n",
    "# create list of paths to each book directory\n",
    "book_directory_paths_list = sorted([x for x in directory_to_process_path.iterdir() if x.is_dir()])\n",
    "\n",
    "# directories to delete because they *should* be ingest directories\n",
    "directory_paths_to_remove_list = []\n",
    "\n",
    "for book_directory_path in book_directory_paths_list:\n",
    "    \n",
    "    # should only be 2 substrings for the directory we want to process\n",
    "    book_directory_path_substrings = str(book_directory_path.name).split('_')\n",
    "        \n",
    "    try: # getting the 2nd split of the string\n",
    "        test_string = book_directory_path_substrings[2]\n",
    "        print(f'Adding {book_directory_path.name} to remove list')\n",
    "        print('')\n",
    "        directory_paths_to_remove_list.append(book_directory_path)\n",
    "        \n",
    "\n",
    "    except IndexError:\n",
    "        \n",
    "        print(f'Processing {book_directory_path.name} . . .')\n",
    "        \n",
    "        # instantiate book\n",
    "        book = ContinuingPublications_Volume(book_directory_path)\n",
    "        \n",
    "        # delete renamed directory and reset backup folder \n",
    "        book.undo_backup()\n",
    "        \n",
    "for directory_path in directory_paths_to_remove_list:\n",
    "    if directory_path.exists():\n",
    "        print(f'Deleting {directory_path.name}')\n",
    "        shutil.rmtree(directory_path)\n",
    "    else:\n",
    "        print(f'{directory_path.name} no longer exists')\n",
    "\n",
    "# create list of paths to each directory\n",
    "directory_paths_list = sorted([x for x in directory_to_process_path.iterdir() if x.is_dir()]) \n",
    "print('')\n",
    "print(f'Directories in {directory_to_process_path.resolve()}')\n",
    "for directory_path in directory_paths_list:\n",
    "    print(directory_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_path = Path('data/Phoenix/work/test/')\n",
    "book = ContinuingPublications_Volume(book_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test into a Zipfile . . .\n",
      "  test.zip is 7.88 MB\n"
     ]
    }
   ],
   "source": [
    "book.create_zip_file(book_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m1\u001b[m\u001b[m \u001b[34m2\u001b[m\u001b[m \u001b[34m3\u001b[m\u001b[m\r\n",
      "\r\n",
      "data/Phoenix/work/test/1:\r\n",
      "summary.tif\r\n",
      "\r\n",
      "data/Phoenix/work/test/2:\r\n",
      "page 1.tif\r\n",
      "\r\n",
      "data/Phoenix/work/test/3:\r\n",
      "index.tif\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R {book_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
